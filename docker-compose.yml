version: '3'
services:
  ## SERVICE1: APACHE SPARK -------------------------------------
  spark:
    image: docker.io/bitnami/spark:3
    container_name: spark-master
    restart: always
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080' # http://localhost:8080 web ui spark
      - '7077:7077' # per connettersi a spark master
      - '4040:4040'
    volumes:
      - ./target:/opt/bitnami/spark/taxi-app/

  spark-worker:
    image: docker.io/bitnami/spark:3
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077 # the url of the master the worker will connect to
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8081:8081' # http://localhost:8081 web ui spark
    volumes:
      - ./target:/opt/bitnami/spark/taxi-app/
    depends_on:
      - spark

  # SERVICE2: HDFS ---------------------------------------------
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - '9870:9870' # http://localhost:9870 web ui HDFS.
      - '9000:9000' #
    volumes:
      - hadoop_namenode:/hadoop/dfs/name # volume di hdfs namenode
      - nifi-hdfs:/etc/hadoop # TODO: serve davvero? volume in comune con nifi
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    depends_on:
      - namenode


#  # SERVICE3: NIFI ----------------------------------------------
  nifi:
    image: apache/nifi:latest
    restart: always
    container_name: nifi
    ports:
      - '8181:8181'   # http://localhost:8181 web ui NiFi
      # - '9000:9000' # serve per connettersi al namenode hdfs
    environment:
      NIFI_WEB_HTTP_PORT: '8181'
    volumes:
      - .nifi:/opt/nifi/nifi-current/ls-target
      - type: bind
        source: .nifi/security/cacerts
        target: /opt/nifi/nifi-current/cacerts
      - nifi-hdfs:/opt/nifi/nifi-current/ls-target/hdfs-conf # Todo: serve davvero? montiamo il volume nifi-hdfs nella cartella hdfs-conf, che è collegata anche in .nifi/hdfs-conf

# nifi salva su HDFS, per vedere il file usa: "hdfs dfs -ls /home/dataset-batch"


# SERVICE4: REDIS ---------------------------------------------
#  redis:
#    image: redis
#    container_name: redis-cache
#    ports:
#      - #to be defined

volumes:
  nifi-hdfs: # volume in comune tra hdfs
  hadoop_datanode:
    driver: local # Dove salvare i dati? Di default è local
    external: false # Il container è stato definito fuori da docker-compose? Di default è false.
  hadoop_namenode:
    driver: local # Dove salvare i dati? Di default è local
    external: false # Il container è stato definito fuori da docker-compose? Di default è false.
#  spark-volume:
#    driver: local # Dove salvare i dati? Di default è local
#    external: false # Il container è stato definito fuori da docker-compose? Di default è false.
