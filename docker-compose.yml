version: '3'
services:

  ## SERVICE3: NIFI ----------------------------------------------
  nifi:
    image: apache/nifi:latest
    restart: always
    container_name: nifi
    ports:
      - '8181:8181'   # http://localhost:8181 web ui NiFi
    #      - '9000:9000' # serve per connettersi al namenode hdfs
    environment:
      NIFI_WEB_HTTP_PORT: '8181'
    volumes:
      - .nifi:/opt/nifi/nifi-current/ls-target
      - type: bind
        source: .nifi/security/cacerts
        target: /opt/nifi/nifi-current/cacerts
      - nifi-hdfs:/opt/nifi/nifi-current/ls-target/hdfs-conf # Todo: serve davvero? montiamo il volume nifi-hdfs nella cartella hdfs-conf, che è collegata anche in .nifi/hdfs-conf

  # nifi salva su HDFS, per vedere il file usa: "hdfs dfs -ls /home/dataset-batch"

  ## SERVICE1: APACHE SPARK -------------------------------------
  spark:
    image: docker.io/bitnami/spark:3
    container_name: spark-master
    restart: always
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080' # http://localhost:8080 web ui spark
      - '7077:7077' # per connettersi a spark master
      - '4040:4040'
    volumes:
      - ./target:/opt/bitnami/spark/taxi-app/
      - .nifi/templates:/home/templates

  spark-worker:
    image: docker.io/bitnami/spark:3
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077 # the url of the master the worker will connect to
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    #    ports:
    #      - '8081:8081' # http://localhost:8081 web ui spark
    volumes:
      - ./target:/opt/bitnami/spark/taxi-app/
    depends_on:
      - spark

  # SERVICE2: HDFS ---------------------------------------------
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - '9870:9870' # http://localhost:9870 web ui HDFS.
      - '9000:9000' #
    volumes:
      - hadoop_namenode:/hadoop/dfs/name # volume di hdfs namenode
      - nifi-hdfs:/etc/hadoop # TODO: serve davvero? volume in comune con nifi
    environment:
      - CLUSTER_NAME=test
      - HDFS_CONF_dfs_replication=1
    env_file:
      - ./hadoop.env

  datanode: # se il datanode va in un ciclo di riavvii, bisogna eliminare tutti i container e volumi di questo compose e riavviare.
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
#    environment:
#      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    depends_on:
      - namenode


# SERVICE4: REDIS ---------------------------------------------
  redis:
    image: redis
    container_name: redis-cache
    ports:
      - '6379:6379'

# SERVICE5: GRAFANA -------------------------------------------
  grafana:
    build:
      context: ./grafana
    container_name: grafana
    ports:
      - '8000:3000'
    volumes:
      - grafana-data:/var/lib/grafana

volumes:
  nifi-hdfs: # volume in comune tra hdfs
  nifi-spark: #volume in comune tra nifi e spark
  hadoop_datanode:
    driver: local # Dove salvare i dati? Di default è local
    external: false # Il container è stato definito fuori da docker-compose? Di default è false.
  hadoop_namenode:
    driver: local # Dove salvare i dati? Di default è local
    external: false # Il container è stato definito fuori da docker-compose? Di default è false.
#  spark-volume:
#    driver: local # Dove salvare i dati? Di default è local
#    external: false # Il container è stato definito fuori da docker-compose? Di default è false.
  grafana-data:
    external: false
